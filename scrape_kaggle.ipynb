{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for APPLE (AAPL)...\n",
      "Error processing APPLE (AAPL): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for TESLA (TSLA)...\n",
      "Error processing TESLA (TSLA): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for NVIDIA (NVDA)...\n",
      "Error processing NVIDIA (NVDA): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for AMAZON (AMZN)...\n",
      "Error processing AMAZON (AMZN): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for MICROSOFT (MSFT)...\n",
      "Error processing MICROSOFT (MSFT): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for META (META)...\n",
      "Error processing META (META): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for ALIBABA (BABA)...\n",
      "Error processing ALIBABA (BABA): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for INTEL (INTC)...\n",
      "Error processing INTEL (INTC): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "Fetching data for HP (HPQ)...\n",
      "Error processing HP (HPQ): Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Convert stock data dictionary to a single DataFrame\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStock\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Convert news sentiment data to DataFrame\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from enum import Enum\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "NEWS_API_KEY = \"ad0b9cea9d414bb99c7ffec0f22b073f\"\n",
    "\n",
    "# Define Stock Enum\n",
    "class Stock(Enum):\n",
    "    APPLE = \"AAPL\"\n",
    "    TESLA = \"TSLA\"\n",
    "    NVIDIA = \"NVDA\"\n",
    "    AMAZON = \"AMZN\"\n",
    "    MICROSOFT = \"MSFT\"\n",
    "    META = \"META\"\n",
    "    ALIBABA = \"BABA\"\n",
    "    INTEL = \"INTC\"\n",
    "    HP = \"HPQ\"\n",
    "\n",
    "# Initialize storage and sentiment analyzer\n",
    "stock_data = {}\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "news_sentiment_data = []\n",
    "\n",
    "# Fetch historical data and news for all stocks\n",
    "for stock in Stock:\n",
    "    try:\n",
    "        print(f\"Fetching data for {stock.name} ({stock.value})...\")\n",
    "        ticker = yf.Ticker(stock.value)\n",
    "        history = ticker.history(period=\"max\")  # Get maximum available history\n",
    "\n",
    "        if history.empty:\n",
    "            print(f\"No data available for {stock.name} ({stock.value}). Skipping...\")\n",
    "            continue\n",
    "\n",
    "        stock_data[stock.name] = history\n",
    "        print(f\"Data for {stock.name} ({stock.value}) fetched successfully!\")\n",
    "\n",
    "        # Fetch news from NewsAPI\n",
    "        print(f\"Fetching news for {stock.name} ({stock.value})...\")\n",
    "        url = f\"https://newsapi.org/v2/everything?q={stock.value}&apiKey={NEWS_API_KEY}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"articles\" not in data or not data[\"articles\"]:\n",
    "            print(f\"No news found for {stock.name} ({stock.value}). Skipping...\")\n",
    "            continue\n",
    "\n",
    "        for article in data[\"articles\"]:\n",
    "            headline = article[\"title\"]\n",
    "            sentiment_score = analyzer.polarity_scores(headline)[\"compound\"]\n",
    "\n",
    "            news_sentiment_data.append([stock.name, headline, sentiment_score, article[\"url\"]])\n",
    "\n",
    "        print(f\"News sentiment analysis completed for {stock.name}!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {stock.name} ({stock.value}): {e}\")\n",
    "\n",
    "# Convert stock data dictionary to a single DataFrame\n",
    "combined_df = pd.concat(stock_data, names=[\"Stock\", \"Date\"])\n",
    "combined_df.reset_index(inplace=True)\n",
    "\n",
    "# Convert news sentiment data to DataFrame\n",
    "news_df = pd.DataFrame(news_sentiment_data, columns=[\"Stock\", \"Headline\", \"Sentiment Score\", \"URL\"])\n",
    "\n",
    "# Save to CSV files\n",
    "combined_df.to_csv(\"stocks_history.csv\", index=False)\n",
    "news_df.to_csv(\"stocks_news_sentiment.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "print(combined_df.head())\n",
    "print(news_df.head())\n",
    "\n",
    "print(\"Stock data saved to stocks_history.csv and news sentiment saved to stocks_news_sentiment.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'tonumpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42312\\964847726.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0maverage_sentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews_sentiment_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Stock\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sentiment Score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Convert the result to a dictionary (vector format)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0maverage_sentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_sentiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0msentiment_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_sentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtonumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Print the sentiment vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'tonumpy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load stock news sentiment data\n",
    "news_sentiment_df = pd.read_csv(\"stocks_news_sentiment.csv\")\n",
    "\n",
    "# Ensure 'Sentiment Score' is numeric\n",
    "news_sentiment_df[\"Sentiment Score\"] = pd.to_numeric(news_sentiment_df[\"Sentiment Score\"], errors=\"coerce\")\n",
    "\n",
    "# Calculate the average sentiment score for each stock\n",
    "average_sentiment = news_sentiment_df.groupby(\"Stock\")[\"Sentiment Score\"].mean()\n",
    "\n",
    "# Convert the result to a dictionary (vector format)\n",
    "average_sentiment = round(average_sentiment, 3)\n",
    "sentiment_vector = average_sentiment.tonumpy()\n",
    "\n",
    "# Print the sentiment vector\n",
    "print(sentiment_vector)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
